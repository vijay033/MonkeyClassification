{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vijay\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(300, 300,..., activation=\"relu\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\vijay\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  \n",
      "C:\\Users\\vijay\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "C:\\Users\\vijay\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", kernel_regularizer=<keras.reg..., units=128)`\n",
      "C:\\Users\\vijay\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n"
     ]
    }
   ],
   "source": [
    "#initialize the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Step 1 Convolution\n",
    "classifier.add(Convolution2D(64,3,3,input_shape=(300,300,3),activation='relu'))\n",
    "#classifier.add(Dropout(0.5))\n",
    "# Step 2 Max Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "# classifier.add(Convolution2D(64,3,3,activation='relu'))\n",
    "# classifier.add(Dropout(0.5))\n",
    "# classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "classifier.add(Convolution2D(64,3,3,activation='relu'))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "# classifier.add(Convolution2D(32,3,3,activation='relu'))\n",
    "# classifier.add(Dropout(0.5))\n",
    "# classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "classifier.add(Convolution2D(32,3,3,activation='relu'))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "\n",
    "# Step 3 Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 Full Connection ( Hidden and Output Layer for Class Prediction)\n",
    "#Hidden Layer\n",
    "classifier.add(Dense(output_dim=128,  activation = 'relu' , kernel_regularizer=regularizers.l2(0.001)))\n",
    "#Output Layer\n",
    "classifier.add(Dense(output_dim=10,  activation = 'softmax' )) # try with 'sigmoid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_136 (Conv2D)          (None, 298, 298, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_133 (MaxPoolin (None, 149, 149, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_137 (Conv2D)          (None, 147, 147, 64)      36928     \n",
      "_________________________________________________________________\n",
      "dropout_96 (Dropout)         (None, 147, 147, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_134 (MaxPoolin (None, 73, 73, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_138 (Conv2D)          (None, 71, 71, 32)        18464     \n",
      "_________________________________________________________________\n",
      "dropout_97 (Dropout)         (None, 71, 71, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_135 (MaxPoolin (None, 35, 35, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_26 (Flatten)         (None, 39200)             0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 128)               5017728   \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 5,076,202\n",
      "Trainable params: 5,076,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "# classifier.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier.compile(Adam(lr = 0.001), loss='categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the CNN to the images\n",
    "# Image augmentation for reducing overfitting - Balancing bias and variance\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1097 images belonging to 10 classes.\n",
      "Found 272 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory('Monkey/training',\n",
    "                                                    target_size=(300, 300),\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory('Monkey/validation',\n",
    "                                                        target_size=(300,300),\n",
    "                                                        batch_size=16,\n",
    "                                                        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 68s 2s/step - loss: 2.6320 - acc: 0.1457 - val_loss: 2.4399 - val_acc: 0.2316\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 51s 1s/step - loss: 2.1532 - acc: 0.2731 - val_loss: 2.1720 - val_acc: 0.3529\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 49s 1s/step - loss: 1.7660 - acc: 0.4005 - val_loss: 1.9513 - val_acc: 0.4228\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 50s 1s/step - loss: 1.5301 - acc: 0.4947 - val_loss: 1.7872 - val_acc: 0.4779\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 49s 1s/step - loss: 1.3713 - acc: 0.5692 - val_loss: 1.7611 - val_acc: 0.5110\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 49s 1s/step - loss: 1.2689 - acc: 0.6096 - val_loss: 1.7300 - val_acc: 0.5147\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 49s 1s/step - loss: 1.2523 - acc: 0.6390 - val_loss: 1.7820 - val_acc: 0.5294\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 50s 1s/step - loss: 1.1529 - acc: 0.6737 - val_loss: 1.6547 - val_acc: 0.5809\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 51s 1s/step - loss: 0.9867 - acc: 0.7168 - val_loss: 1.6069 - val_acc: 0.5478\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 48s 1s/step - loss: 1.0515 - acc: 0.7076 - val_loss: 1.6069 - val_acc: 0.5735\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 52s 2s/step - loss: 0.9446 - acc: 0.7392 - val_loss: 1.4660 - val_acc: 0.6397\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 51s 2s/step - loss: 0.8500 - acc: 0.7739 - val_loss: 1.4150 - val_acc: 0.6360\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 48s 1s/step - loss: 0.8373 - acc: 0.7830 - val_loss: 1.4716 - val_acc: 0.6103\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 52s 2s/step - loss: 0.8620 - acc: 0.7761 - val_loss: 1.5923 - val_acc: 0.5772\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 49s 1s/step - loss: 0.8619 - acc: 0.7760 - val_loss: 1.4376 - val_acc: 0.6287\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 51s 1s/step - loss: 0.7857 - acc: 0.8153 - val_loss: 1.4374 - val_acc: 0.6103\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 51s 1s/step - loss: 0.7510 - acc: 0.8097 - val_loss: 1.4130 - val_acc: 0.6654\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 49s 1s/step - loss: 0.7002 - acc: 0.8464 - val_loss: 1.3494 - val_acc: 0.6213\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 49s 1s/step - loss: 0.6782 - acc: 0.8538 - val_loss: 1.3916 - val_acc: 0.6471\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 50s 1s/step - loss: 0.6337 - acc: 0.8661 - val_loss: 1.3912 - val_acc: 0.6397\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 52s 2s/step - loss: 0.6216 - acc: 0.8750 - val_loss: 1.3382 - val_acc: 0.6471\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 48s 1s/step - loss: 0.6827 - acc: 0.8740 - val_loss: 1.3928 - val_acc: 0.6287\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 55s 2s/step - loss: 0.8164 - acc: 0.8107 - val_loss: 1.5124 - val_acc: 0.6066\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 50s 1s/step - loss: 0.8459 - acc: 0.8119 - val_loss: 1.4936 - val_acc: 0.6103\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 50s 1s/step - loss: 0.6421 - acc: 0.8791 - val_loss: 1.3445 - val_acc: 0.6618\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 53s 2s/step - loss: 0.6134 - acc: 0.8850 - val_loss: 1.3937 - val_acc: 0.6471\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 49s 1s/step - loss: 0.6992 - acc: 0.8611 - val_loss: 1.4192 - val_acc: 0.6434\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 48s 1s/step - loss: 0.6324 - acc: 0.8888 - val_loss: 1.4349 - val_acc: 0.6434\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 48s 1s/step - loss: 0.5974 - acc: 0.9126 - val_loss: 1.3318 - val_acc: 0.6507\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 46s 1s/step - loss: 0.5412 - acc: 0.9181 - val_loss: 1.3099 - val_acc: 0.6507\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 46s 1s/step - loss: 0.5527 - acc: 0.9145 - val_loss: 1.3677 - val_acc: 0.6213\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 47s 1s/step - loss: 0.5754 - acc: 0.9030 - val_loss: 1.3320 - val_acc: 0.6397\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 48s 1s/step - loss: 0.7331 - acc: 0.8658 - val_loss: 1.4664 - val_acc: 0.6213\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 48s 1s/step - loss: 0.6295 - acc: 0.8984 - val_loss: 1.3901 - val_acc: 0.6654\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 46s 1s/step - loss: 0.5379 - acc: 0.9227 - val_loss: 1.3400 - val_acc: 0.6434\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 46s 1s/step - loss: 0.5132 - acc: 0.9375 - val_loss: 1.2845 - val_acc: 0.7059\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 49s 1s/step - loss: 0.5018 - acc: 0.9402 - val_loss: 1.2961 - val_acc: 0.6801\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 48s 1s/step - loss: 0.4628 - acc: 0.9439 - val_loss: 1.2403 - val_acc: 0.6801\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 48s 1s/step - loss: 0.4853 - acc: 0.9384 - val_loss: 1.2397 - val_acc: 0.6765\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 46s 1s/step - loss: 0.5853 - acc: 0.9044 - val_loss: 1.3993 - val_acc: 0.6250\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 46s 1s/step - loss: 0.5252 - acc: 0.9329 - val_loss: 1.3744 - val_acc: 0.6471\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 50s 1s/step - loss: 0.5604 - acc: 0.9301 - val_loss: 1.4172 - val_acc: 0.6250\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 49s 1s/step - loss: 0.5644 - acc: 0.9205 - val_loss: 1.3839 - val_acc: 0.6176\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 47s 1s/step - loss: 0.5349 - acc: 0.9333 - val_loss: 1.4097 - val_acc: 0.6544\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 48s 1s/step - loss: 0.5223 - acc: 0.9319 - val_loss: 1.3641 - val_acc: 0.6691\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 53s 2s/step - loss: 0.5166 - acc: 0.9311 - val_loss: 1.3276 - val_acc: 0.6507\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 55s 2s/step - loss: 0.5193 - acc: 0.9407 - val_loss: 1.3244 - val_acc: 0.6471\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 56s 2s/step - loss: 0.5093 - acc: 0.9375 - val_loss: 1.3294 - val_acc: 0.6581\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 53s 2s/step - loss: 0.5145 - acc: 0.9411 - val_loss: 1.4365 - val_acc: 0.6324\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 52s 2s/step - loss: 0.5882 - acc: 0.9214 - val_loss: 1.3886 - val_acc: 0.6618\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 50s 1s/step - loss: 0.5534 - acc: 0.9356 - val_loss: 1.3889 - val_acc: 0.6434\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 51s 1s/step - loss: 0.4869 - acc: 0.9503 - val_loss: 1.3417 - val_acc: 0.6654\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 50s 1s/step - loss: 0.5579 - acc: 0.9370 - val_loss: 1.4246 - val_acc: 0.6875\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 54s 2s/step - loss: 0.5458 - acc: 0.9366 - val_loss: 1.3551 - val_acc: 0.6728\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 48s 1s/step - loss: 0.5275 - acc: 0.9388 - val_loss: 1.3485 - val_acc: 0.6691\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 52s 2s/step - loss: 0.5019 - acc: 0.9467 - val_loss: 1.3025 - val_acc: 0.6765\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 49s 1s/step - loss: 0.4713 - acc: 0.9549 - val_loss: 1.3187 - val_acc: 0.6618\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 49s 1s/step - loss: 0.4551 - acc: 0.9586 - val_loss: 1.3329 - val_acc: 0.6618\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 50s 1s/step - loss: 0.4472 - acc: 0.9614 - val_loss: 1.3440 - val_acc: 0.6324\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 51s 1s/step - loss: 0.4859 - acc: 0.9499 - val_loss: 1.3606 - val_acc: 0.6324\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 47s 1s/step - loss: 0.5273 - acc: 0.9375 - val_loss: 1.3521 - val_acc: 0.6434\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 49s 1s/step - loss: 0.5171 - acc: 0.9370 - val_loss: 1.3249 - val_acc: 0.6765\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 52s 2s/step - loss: 0.5307 - acc: 0.9398 - val_loss: 1.3612 - val_acc: 0.6544\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 47s 1s/step - loss: 0.4578 - acc: 0.9660 - val_loss: 1.4053 - val_acc: 0.6324\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 55s 2s/step - loss: 0.4459 - acc: 0.9568 - val_loss: 1.3146 - val_acc: 0.6654\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 50s 1s/step - loss: 0.4018 - acc: 0.9798 - val_loss: 1.2985 - val_acc: 0.6949\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 52s 2s/step - loss: 0.3896 - acc: 0.9798 - val_loss: 1.3305 - val_acc: 0.6360\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 49s 1s/step - loss: 0.4156 - acc: 0.9678 - val_loss: 1.3404 - val_acc: 0.6581\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 50s 1s/step - loss: 0.4545 - acc: 0.9531 - val_loss: 1.3582 - val_acc: 0.6765\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 48s 1s/step - loss: 0.5285 - acc: 0.9306 - val_loss: 1.4032 - val_acc: 0.6250\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 50s 1s/step - loss: 0.5345 - acc: 0.9338 - val_loss: 1.4697 - val_acc: 0.6471\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 51s 1s/step - loss: 0.6182 - acc: 0.9122 - val_loss: 1.4450 - val_acc: 0.6471\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 52s 2s/step - loss: 0.5731 - acc: 0.9301 - val_loss: 1.4178 - val_acc: 0.6581\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 47s 1s/step - loss: 0.5965 - acc: 0.9324 - val_loss: 1.5188 - val_acc: 0.6324\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 52s 2s/step - loss: 0.6060 - acc: 0.9177 - val_loss: 1.5053 - val_acc: 0.6324\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 49s 1s/step - loss: 0.5461 - acc: 0.9435 - val_loss: 1.5268 - val_acc: 0.6397\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 46s 1s/step - loss: 0.5271 - acc: 0.9430 - val_loss: 1.3756 - val_acc: 0.6691\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 53s 2s/step - loss: 0.5203 - acc: 0.9522 - val_loss: 1.4699 - val_acc: 0.6287\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 54s 2s/step - loss: 0.5143 - acc: 0.9568 - val_loss: 1.4249 - val_acc: 0.6287\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 48s 1s/step - loss: 0.4603 - acc: 0.9646 - val_loss: 1.3410 - val_acc: 0.6544\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 49s 1s/step - loss: 0.4713 - acc: 0.9642 - val_loss: 1.3786 - val_acc: 0.6397\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 50s 1s/step - loss: 0.4604 - acc: 0.9673 - val_loss: 1.3486 - val_acc: 0.6875\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 47s 1s/step - loss: 0.4433 - acc: 0.9733 - val_loss: 1.3980 - val_acc: 0.6765\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 49s 1s/step - loss: 0.5547 - acc: 0.9338 - val_loss: 1.4285 - val_acc: 0.6397\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 48s 1s/step - loss: 0.4594 - acc: 0.9609 - val_loss: 1.4827 - val_acc: 0.6397\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 48s 1s/step - loss: 0.5128 - acc: 0.9485 - val_loss: 1.4531 - val_acc: 0.6434\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 48s 1s/step - loss: 0.6240 - acc: 0.9095 - val_loss: 1.5144 - val_acc: 0.6029\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 48s 1s/step - loss: 0.5598 - acc: 0.9397 - val_loss: 1.4893 - val_acc: 0.6507\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 48s 1s/step - loss: 0.5230 - acc: 0.9527 - val_loss: 1.3968 - val_acc: 0.6471\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 50s 1s/step - loss: 0.5271 - acc: 0.9421 - val_loss: 1.3671 - val_acc: 0.6801\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 50s 1s/step - loss: 0.5179 - acc: 0.9508 - val_loss: 1.4710 - val_acc: 0.6581\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 50s 1s/step - loss: 0.5252 - acc: 0.9430 - val_loss: 1.2971 - val_acc: 0.6949\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 50s 1s/step - loss: 0.4615 - acc: 0.9637 - val_loss: 1.4000 - val_acc: 0.6654\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 48s 1s/step - loss: 0.5276 - acc: 0.9389 - val_loss: 1.4935 - val_acc: 0.6324\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 47s 1s/step - loss: 0.5479 - acc: 0.9255 - val_loss: 1.3716 - val_acc: 0.6765\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 48s 1s/step - loss: 0.5186 - acc: 0.9527 - val_loss: 1.4365 - val_acc: 0.6397\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 46s 1s/step - loss: 0.5538 - acc: 0.9458 - val_loss: 1.3780 - val_acc: 0.6581\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 48s 1s/step - loss: 0.4970 - acc: 0.9572 - val_loss: 1.3079 - val_acc: 0.6801\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 47s 1s/step - loss: 0.5002 - acc: 0.9632 - val_loss: 1.3125 - val_acc: 0.6985\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 48s 1s/step - loss: 0.4685 - acc: 0.9696 - val_loss: 1.4195 - val_acc: 0.6360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2402c433860>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#steps_per_epoch - no of training data image\n",
    "#validation_steps - no of testing data image\n",
    "classifier.fit_generator(train_generator,\n",
    "                         steps_per_epoch=34, #1097/32\n",
    "                         epochs=100,\n",
    "                         validation_data=validation_generator,\n",
    "                         validation_steps=17)  #272/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 8 3 8 3 4 7 3 7 3 9 5 2 4 4 1]\n",
      "(16,)\n",
      "(16,)\n",
      "Predicted class for monkey is 6, and the actual class of monkey is 6\n",
      "Predicted class for monkey is 8, and the actual class of monkey is 1\n",
      "Predicted class for monkey is 3, and the actual class of monkey is 3\n",
      "Predicted class for monkey is 8, and the actual class of monkey is 7\n",
      "Predicted class for monkey is 3, and the actual class of monkey is 2\n",
      "Predicted class for monkey is 4, and the actual class of monkey is 9\n",
      "Predicted class for monkey is 7, and the actual class of monkey is 7\n",
      "Predicted class for monkey is 3, and the actual class of monkey is 3\n",
      "Predicted class for monkey is 7, and the actual class of monkey is 7\n",
      "Predicted class for monkey is 3, and the actual class of monkey is 4\n",
      "Predicted class for monkey is 9, and the actual class of monkey is 9\n",
      "Predicted class for monkey is 5, and the actual class of monkey is 5\n",
      "Predicted class for monkey is 2, and the actual class of monkey is 2\n",
      "Predicted class for monkey is 4, and the actual class of monkey is 4\n",
      "Predicted class for monkey is 4, and the actual class of monkey is 4\n",
      "Predicted class for monkey is 1, and the actual class of monkey is 3\n",
      "[[0 0 0 0 0 0 0 1 0]\n",
      " [0 1 1 0 0 0 0 0 0]\n",
      " [1 0 2 0 0 0 0 0 0]\n",
      " [0 0 1 2 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 2 1 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "test_imgs,test_labels = next(validation_generator)\n",
    "predicted = classifier.predict_classes(test_imgs)\n",
    "predicted_ = np.argmax(to_categorical(predicted), axis=1)\n",
    "print(predicted_)\n",
    "print(predicted_.shape)\n",
    "#print(test_labels)\n",
    "\n",
    "rrow = len(test_labels)\n",
    "ccol = np.size(test_labels,1) \n",
    "\n",
    "# print(rrow)\n",
    "# print(ccol)\n",
    "\n",
    "actual_labels = np.arange(rrow)\n",
    "actual_labels.reshape(rrow,)\n",
    "print(actual_labels.shape)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(rrow):\n",
    "     for j in range(ccol):\n",
    "         if test_labels[i][j] == 1:\n",
    "             actual_labels[i] = j\n",
    "            \n",
    "for i, j in zip(predicted_,actual_labels):\n",
    "    print( \"Predicted class for monkey is {}, and the actual class of monkey is {}\".format(i,j))\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(actual_labels,predicted_)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_imgs,test_labels = next(validation_generator)\n",
    "# predictions = classifier.predict_generator(validation_generator,steps=1,verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
